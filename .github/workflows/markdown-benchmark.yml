name: Markdown Performance

on:
  pull_request:
    paths:
      - 'packages/x-markdown/**'
      - '.github/workflows/benchmark.yml'
  push:
    branches:
      - main
      - feature_markdown_benchmark
    paths:
      - 'packages/x-markdown/**'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Cache node_modules
        uses: actions/cache@v4
        with:
          path: |
            node_modules
            packages/*/node_modules
          key: ${{ runner.os }}-node-modules-${{ hashFiles('package.json', 'packages/*/package.json') }}
          restore-keys: |
            ${{ runner.os }}-node-modules-

      - name: Install dependencies
        run: npm install

      - name: Setup Playwright
        run: |
          cd packages/x-markdown
          npx playwright install --with-deps chromium

      - name: Run benchmark
        id: benchmark
        run: |
          cd packages/x-markdown
          npm run benchmark
        continue-on-error: true

      - name: Download benchmark baseline (if exists)
        uses: actions/cache@v4
        with:
          path: packages/x-markdown/benchmark-baseline.json
          key: benchmark-baseline-${{ github.base_ref || github.ref_name }}

      - name: Check benchmark results exist
        id: check-results
        run: |
          cd packages/x-markdown/src/XMarkdown/__benchmark__
          if [ ! -f "./test-results/benchmark-results.json" ]; then
            echo "âŒ Benchmark results file not found. The benchmark may have failed to run."
            mkdir -p test-results
            echo '[]' > ./test-results/benchmark-results.json
            echo "report_generated=false" >> $GITHUB_OUTPUT
          else
            echo "report_generated=true" >> $GITHUB_OUTPUT
          fi

      - name: Check performance thresholds
        id: check
        if: steps.check-results.outputs.report_generated == 'true'
        run: |
          cd packages/x-markdown/src/XMarkdown/__benchmark__
          node ./scripts/check-performance.js \
            ./test-results/benchmark-results.json \
            ../../../benchmark-baseline.json \
            ./benchmark-check-report.txt || true
        continue-on-error: true

      - name: Generate PR comment
        id: comment
        if: github.event_name == 'pull_request'
        run: |
          cd packages/x-markdown/src/XMarkdown/__benchmark__

          # æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶æ˜¯å¦å­˜åœ¨
          if [ -f "./benchmark-check-report.txt" ]; then
            REPORT=$(cat ./benchmark-check-report.txt)
          else
            REPORT="âš ï¸ Performance benchmark report not found. This might indicate the benchmark did not complete successfully."
          fi

          # ç”Ÿæˆ JSON è¾“å‡ºä¾›åç»­æ­¥éª¤ä½¿ç”¨
          echo "report<<EOF" >> $GITHUB_OUTPUT
          echo "$REPORT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const report = `${{ steps.comment.outputs.report }}`;

            // æŸ¥æ‰¾ç°æœ‰çš„è¯„è®º
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' &&
              comment.body.includes('ğŸ“Š Performance Benchmark Report')
            );

            const commentBody = report + '\n\n---\n*This comment is automatically generated by the Benchmark CI workflow.*';

            if (botComment) {
              // æ›´æ–°ç°æœ‰è¯„è®º
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: commentBody
              });
            } else {
              // åˆ›å»ºæ–°è¯„è®º
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: commentBody
              });
            }

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            packages/x-markdown/src/XMarkdown/__benchmark__/test-results/
            packages/x-markdown/src/XMarkdown/__benchmark__/benchmark-check-report.txt
          retention-days: 30

      - name: Update baseline (on main branch)
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/feature_markdown_benchmark')
        run: |
          cd packages/x-markdown
          cp src/XMarkdown/__benchmark__/test-results/benchmark-results.json benchmark-baseline.json

      - name: Save baseline to cache
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/feature_markdown_benchmark')
        uses: actions/cache@v4
        with:
          path: packages/x-markdown/benchmark-baseline.json
          key: benchmark-baseline-${{ github.ref_name }}

      - name: Check if benchmark failed
        if: steps.check.outcome == 'failure'
        run: |
          echo "::error::Performance benchmark failed! Please check the results above."
          exit 1

      - name: Status check
        if: always()
        run: |
          if [ "${{ steps.benchmark.outcome }}" == "failure" ]; then
            echo "::error::Benchmark execution failed!"
            exit 1
          elif [ "${{ steps.check.outcome }}" == "failure" ]; then
            echo "::warning::Performance thresholds not met! Check the report above for details."
            echo "âš ï¸ This is a warning only and will not block the PR."
          else
            echo "âœ… All checks passed!"
          fi
